{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3266,
     "status": "ok",
     "timestamp": 1565497694833,
     "user": {
      "displayName": "Charles LL",
      "photoUrl": "",
      "userId": "05619559028255365437"
     },
     "user_tz": -600
    },
    "id": "ZtpeeRQzcNby",
    "outputId": "8338f3c3-f8a1-4494-a183-ad5a3df2c65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVAILABLE?  True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd # manipulate dataframes\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np\n",
    "\n",
    "import time, h5py, neuravi, torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "# First we check if CUDA is available\n",
    "print(\"CUDA AVAILABLE? \",torch.cuda.is_available())\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "      \n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "# Fixing random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training function for several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(ds,nb_neurons,nb_layers,p_drop, name, device, patience=100, min_delta=0.05):\n",
    "    \n",
    "    neuralmodel = neuravi.model(4,nb_neurons,nb_layers,ds.nb_channels_raman,p_drop=p_drop) # declaring model\n",
    "\n",
    "    optimizer = torch.optim.Adam(neuralmodel.parameters(), lr = 0.001) # optimizer\n",
    "\n",
    "    # the criterion : MSE\n",
    "    criterion = torch.nn.MSELoss() # criterion for match, sent on device\n",
    "    criterion.to(device)\n",
    "\n",
    "    neuralmodel.output_bias_init() # we initialize the output bias\n",
    "    neuralmodel.to(device) # we send the neural net on device\n",
    "    \n",
    "    # pretraining\n",
    "    neuralmodel, record_pretrain_loss, record_prevalid_loss = neuravi.training(neuralmodel,ds,criterion,optimizer,name,\n",
    "                                                                               verbose=False, mode=\"pretrain\")\n",
    "                \n",
    "    # training\n",
    "    neuralmodel, record_train_loss, record_valid_loss = neuravi.training(neuralmodel,ds,criterion,optimizer,name,\n",
    "                                                                         train_patience=patience,min_delta=min_delta,verbose=False)\n",
    "\n",
    "    # to avoid any problem with CUDA memory...\n",
    "    del neuralmodel, criterion\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset size experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879674,
     "status": "ok",
     "timestamp": 1565498592905,
     "user": {
      "displayName": "Charles LL",
      "photoUrl": "",
      "userId": "05619559028255365437"
     },
     "user_tz": -600
    },
    "id": "a2pNE0yNe1CD",
    "outputId": "a85bb203-1d08-4879-84da-02ef81255c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 0 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/charles/anaconda3/envs/ml/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "100%|██████████| 10/10 [05:14<00:00, 31.46s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 1 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:35<00:00, 39.53s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 2 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:53<00:00, 41.31s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 3 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:19<00:00, 31.95s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 4 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:48<00:00, 34.88s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 5 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:11<00:00, 37.18s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 6 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:23<00:00, 20.34s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 7 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:48<00:00, 22.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# paths of data and results\n",
    "path_data = [\"./data/DataSet_0p10val.hdf5\",\n",
    "             \"./data/DataSet_0p20val.hdf5\",\n",
    "             \"./data/DataSet_0p30val.hdf5\",\n",
    "             \"./data/DataSet_0p40val.hdf5\",\n",
    "             \"./data/DataSet_0p50val.hdf5\",\n",
    "             \"./data/DataSet_0p60val.hdf5\",\n",
    "             \"./data/DataSet_0p70val.hdf5\",\n",
    "             \"./data/DataSet_0p80val.hdf5\"]\n",
    "save_names = [\"./model/exp_trainsize/model_l4_n200_p10_data0p10val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p20val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p30val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p40val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p50val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p60val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p70val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p10_data0p80val\"]\n",
    "\n",
    "# the selected architecture\n",
    "nb_neurons = 300\n",
    "nb_layers = 4\n",
    "p_drop = 0.1\n",
    "\n",
    "#\n",
    "# Main loop for the experiment\n",
    "#\n",
    "for i in range(len(path_data)):\n",
    "    print('Experiment on dataset {} started...'.format(i))\n",
    "    ds = neuravi.data_loader(path_data,\n",
    "                         \"./data/NKAS_Raman.hdf5\",\n",
    "                         \"./data/NKAS_density.hdf5\",\n",
    "                         \"./data/NKAS_optical.hdf5\",device)\n",
    "    \n",
    "    for j in tqdm(range(10)):\n",
    "        train_model(ds, nb_neurons, nb_layers, p_drop, \n",
    "                    save_names[i]+\"_{}.pth\".format(j), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1FGNlKke3PC"
   },
   "source": [
    "# Architecture experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/ml/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "100%|██████████| 2000/2000 [26:31:37<00:00, 47.75s/it]   \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Start calculations\n",
    "#\n",
    "nb_exp = 2000\n",
    "nb_neurons = np.random.randint(10,high=500,size=nb_exp)\n",
    "nb_layers = np.random.randint(1,high=10,size=nb_exp)\n",
    "p_drop = np.around(np.random.random_sample(nb_exp)*0.5,2)\n",
    "\n",
    "# custom data loader, automatically sent to device\n",
    "ds = neuravi.data_loader(\"./data/DataSet_0p20val.hdf5\",\n",
    "                         \"./data/NKAS_Raman.hdf5\",\n",
    "                         \"./data/NKAS_density.hdf5\",\n",
    "                         \"./data/NKAS_optical.hdf5\",\n",
    "                         device)\n",
    "    \n",
    "for i in tqdm(range(nb_exp)):\n",
    "        \n",
    "    # name for saving\n",
    "    name = \"./model/exp_arch/l\"+str(nb_layers[i])+\"_n\"+str(nb_neurons[i])+\"_p\"+str(p_drop[i])+\".pth\"\n",
    "    \n",
    "    train_model(ds,nb_neurons[i],nb_layers[i],p_drop[i], name, device, patience = 100, min_delta=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_datasetsize_exp.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

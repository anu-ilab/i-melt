{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_loss_experiment.ipynb","version":"0.3.2","provenance":[{"file_id":"1pyCJHFWF3kQnPEODWuaOJ_CNv3Xpl7iS","timestamp":1557992100097},{"file_id":"1EwabwOAxjcKaayDdcgvKHS-8H9MkCJSn","timestamp":1557905521210}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"maVRVSAFHDwa","colab_type":"code","colab":{}},"source":["#!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0SePNd0dLJc","colab_type":"code","outputId":"abffa3fe-ec5e-4ed2-ac84-97bd796b8b4d","executionInfo":{"status":"ok","timestamp":1558055182469,"user_tz":-600,"elapsed":2670,"user":{"displayName":"Charles LL","photoUrl":"","userId":"05619559028255365437"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Library loading\n","%matplotlib inline\n","\n","import pandas as pd # manipulate dataframes\n","import matplotlib.pyplot as plt # plotting\n","import matplotlib\n","import numpy as np\n","import time\n","\n","from sklearn.metrics import mean_squared_error\n","import h5py\n","\n","# Check torch install\n","try:\n","  import torch\n","except:\n","  print(\"Starting a session, torch not installed, installing...\")\n","  !pip3 install torch # we install torch if not installed\n","  import torch\n","\n","# First we check if CUDA is available\n","print(\"CUDA AVAILABLE? \",torch.cuda.is_available())\n","\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","      \n","device = get_default_device()\n","print(device)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["CUDA AVAILABLE?  True\n","cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_kdpEo5uGMlR","colab_type":"code","colab":{}},"source":["### Download datasets\n","downloaded = drive.CreateFile({'id':\"1femDl-mpNeoLrbeBzfoLF3A_pNi2zR7D\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('NKAS_DataSet.hdf5')  \n","\n","downloaded = drive.CreateFile({'id':\"1s62a9Tfgmht0lUCjlAwVjW56vbngWE26\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('DataSet_0p20val.hdf5')  \n","\n","downloaded = drive.CreateFile({'id':\"1FxLvyBgmfQ17xctfOjzEvWcNmGa9F4sR\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('NKAS_density.hdf5')  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7Rj949aMM1n","colab_type":"text"},"source":["# Model function"]},{"cell_type":"code","metadata":{"id":"pzVAs5_NfwG-","colab_type":"code","colab":{}},"source":["class model(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, nb_channels_raman,p_drop=0.5):\n","        super(model, self).__init__()\n","        \n","        # init parameters\n","        self.input_size = input_size\n","        self.hidden_size  = hidden_size\n","        self.num_layers  = num_layers\n","        self.nb_channels_raman = nb_channels_raman\n","        \n","        # network related torch stuffs\n","        self.relu = torch.nn.ReLU()\n","        self.dropout = torch.nn.Dropout(p=p_drop)\n","\n","        self.linears = torch.nn.ModuleList([torch.nn.Linear(input_size, self.hidden_size)])\n","        self.linears.extend([torch.nn.Linear(self.hidden_size, self.hidden_size) for i in range(1, self.num_layers)])\n","            \n","#         self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)        \n","#         self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n","#         self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n","\n","        self.out_thermo = torch.nn.Linear(self.hidden_size, 6) # Linear output\n","        self.out_raman = torch.nn.Linear(self.hidden_size, self.nb_channels_raman) # Linear output\n","    \n","    def forward(self, x):\n","        \"\"\"core neural network\"\"\"\n","        # Feedforward\n","        for layer in self.linears:\n","            x = self.dropout(self.relu(layer(x)))\n","        return x\n","#         hidden1 = self.fc1(x)\n","#         relu1 = self.dropout(self.relu(hidden1))\n","#         hidden2 = self.fc2(relu1)\n","#         relu2 = self.dropout(self.relu(hidden2))\n","#         hidden3 = self.fc3(relu2)\n","#         relu3 = self.dropout(self.relu(hidden3))        \n","#         return relu3 # return last layer\n","    \n","    def output_bias_init(self):\n","        \"\"\"bias initialisation for self.out_thermo\n","        \n","        positions are Tg, Sconf(Tg), Ae, A_am, density, fragility (MYEGA one)\n","        \"\"\"\n","        self.out_thermo.bias = torch.nn.Parameter(data=torch.tensor([np.log(1000.),np.log(10.),-1.5,-1.5,np.log(2.3),np.log(20.0)]))\n","    \n","    def at_gfu(self,x):\n","        \"\"\"calculate atom per gram formula unit\n","\n","        assumes rows are sio2 al2o3 na2o k2o\n","        \"\"\"\n","        out = 3.0*x[:,0] + 5.0*x[:,1] + 3.0*x[:,2] + 3.0*x[:,3]\n","        return torch.reshape(out, (out.shape[0], 1))\n","\n","    def aCpl(self,x):\n","        \"\"\"calculate term a in equation Cpl = qCpl + bCpl*T\n","        \"\"\"\n","        out = 81.37*x[:,0] + 27.21*x[:,1] + 100.6*x[:,2]  + 50.13*x[:,3] + x[:,0]*(x[:,3]*x[:,3])*151.7\n","        return torch.reshape(out, (out.shape[0], 1))\n","\n","    def b_calc(self,x):\n","        \"\"\"calculate term b in equation Cpl = aCpl + b*T\n","        \"\"\"\n","        out = 0.09428*x[:,1] + 0.01578*x[:,3]\n","        return torch.reshape(out, (out.shape[0], 1))\n","\n","    def ap_calc(self,x):\n","        \"\"\"calculate term ap in equation dS = ap ln(T/Tg) + b(T-Tg)\n","        \"\"\"\n","        out = self.aCpl(x) - 3.0*8.314462*self.at_gfu(x)\n","        return torch.reshape(out, (out.shape[0], 1))\n","    \n","    def dCp(self,x,T): \n","        out = self.ap_calc(x)*(torch.log(T)-torch.log(self.tg(x))) + self.b_calc(x)*(T-self.tg(x))\n","        return torch.reshape(out, (out.shape[0], 1))\n","     \n","    def raman_pred(self,x):\n","        \"\"\"Raman predicted spectra\"\"\"\n","        return self.out_raman(self.forward(x))\n","      \n","    def tg(self,x):\n","        \"\"\"glass transition temperature Tg\"\"\"\n","        out = torch.exp(self.out_thermo(self.forward(x))[:,0])\n","        return torch.reshape(out, (out.shape[0], 1))\n","      \n","    def sctg(self,x):\n","        \"\"\"configurational entropy at Tg\"\"\"\n","        out = torch.exp(self.out_thermo(self.forward(x))[:,1])\n","        return torch.reshape(out, (out.shape[0], 1))\n","    \n","    def ae(self,x):\n","        \"\"\"Ae parameter in Adam and Gibbs and MYEGA\"\"\"\n","        out = self.out_thermo(self.forward(x))[:,2]\n","        return torch.reshape(out, (out.shape[0], 1))\n","      \n","    def a_am(self,x):\n","        \"\"\"A parameter for Avramov-Mitchell\"\"\"\n","        out = self.out_thermo(self.forward(x))[:,3]\n","        return torch.reshape(out, (out.shape[0], 1))\n","      \n","    def density(self,x):\n","        \"\"\"glass density\"\"\"\n","        out = torch.exp(self.out_thermo(self.forward(x))[:,4])\n","        return torch.reshape(out, (out.shape[0], 1))\n","    \n","    def fragility(self,x):\n","        \"\"\"melt fragility\"\"\"\n","        out = torch.exp(self.out_thermo(self.forward(x))[:,5])\n","        return torch.reshape(out, (out.shape[0], 1))\n","    \n","    def be(self,x):\n","        \"\"\"Be term in Adam-Gibbs eq given Ae, Tg and Scong(Tg)\"\"\"\n","        return (12.0-self.ae(x))*(self.tg(x)*self.sctg(x))\n","      \n","    def ag(self,x,T):\n","        \"\"\"viscosity from the Adam-Gibbs equation, given chemistry X and temperature T\n","        \"\"\"\n","        return self.ae(x) + self.be(x) / (T* (self.sctg(x) + self.dCp(x, T)))\n","\n","    def myega(self,x, T):\n","        \"\"\"viscosity frself.linears = nn.ModuleList([nn.Linear(input_size, layers_size)])\n","     self.linears.extend([nn.Linear(layers_size, layers_size) for i in range(1, self.num_layers-1)])\n","    om the MYEGA equation, given entries X and temperature T\n","        \"\"\"\n","        return self.ae(x) + (12.0 - self.ae(x))*(self.tg(x)/T)*torch.exp((self.fragility(x)/(12.0-self.ae(x))-1.0)*(self.tg(x)/T-1.0))\n","      \n","    def am(self,x, T):\n","        \"\"\"viscosity from the Avramov-Mitchell equation, given entries X and temperature T\n","        \"\"\"\n","        return self.a_am(x) + (12.0 - self.a_am(x))*(self.tg(x)/T)**(self.fragility(x)/12.0)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U13abpURpfDw","colab_type":"text"},"source":["# General function"]},{"cell_type":"code","metadata":{"id":"nqtfOttCdVto","colab_type":"code","colab":{}},"source":["def train_model(path_data,nb_neurons,nb_layers,p_drop, name, pretrain_patience = 500, train_patience=1000):\n","\n","    path_raman = \"./NKAS_DataSet.hdf5\"\n","    path_density = \"./NKAS_density.hdf5\"\n","\n","    f = h5py.File(path_data, 'r')\n","    \n","    # Entropy dataset\n","    X_entropy_train = f[\"X_entropy_train\"].value\n","    y_entropy_train = f[\"y_entropy_train\"].value\n","\n","    X_entropy_valid = f[\"X_entropy_valid\"].value\n","    y_entropy_valid = f[\"y_entropy_valid\"].value\n","\n","    X_entropy_test = f[\"X_entropy_test\"].value\n","    y_entropy_test = f[\"y_entropy_test\"].value\n","\n","    # Viscosity dataset\n","    X_train = f[\"X_train\"].value\n","    y_train = f[\"y_train\"].value\n","\n","    X_valid = f[\"X_valid\"].value\n","    y_valid = f[\"y_valid\"].value\n","\n","    X_test = f[\"X_test\"].value\n","    y_test = f[\"y_test\"].value\n","\n","    # Tg dataset\n","    X_tg_train = f[\"X_tg_train\"].value\n","    X_tg_valid= f[\"X_tg_valid\"].value\n","    X_tg_test = f[\"X_tg_test\"].value\n","\n","    y_tg_train = f[\"y_tg_train\"].value\n","    y_tg_valid = f[\"y_tg_valid\"].value\n","    y_tg_test = f[\"y_tg_test\"].value\n","\n","    f.close()\n","\n","    # Raman dataset\n","    f = h5py.File(path_raman, 'r')\n","    X_raman_train = f[\"X_raman_train\"].value\n","    y_raman_train = f[\"y_raman_train\"].value\n","    X_raman_valid = f[\"X_raman_test\"].value\n","    y_raman_valid = f[\"y_raman_test\"].value\n","    f.close()\n","\n","    # Density dataset\n","    f = h5py.File(path_density, 'r')\n","    X_density_train = f[\"X_density_train\"].value\n","    X_density_valid = f[\"X_density_valid\"].value\n","    X_density_test = f[\"X_density_test\"].value\n","\n","    y_density_train = f[\"y_density_train\"].value\n","    y_density_valid = f[\"y_density_valid\"].value\n","    y_density_test = f[\"y_density_test\"].value\n","    f.close()\n","\n","    # grabbing number of Raman channels\n","    nb_channels_raman = y_raman_valid.shape[1]\n","\n","    # preparing data\n","\n","    # viscosity\n","    x_visco_train = torch.FloatTensor(X_train[:,0:4]).to(device)\n","    T_visco_train = torch.FloatTensor(X_train[:,4].reshape(-1,1)).to(device)\n","    y_visco_train = torch.FloatTensor(y_train[:,0].reshape(-1,1)).to(device)\n","\n","    x_visco_valid = torch.FloatTensor(X_valid[:,0:4]).to(device)\n","    T_visco_valid = torch.FloatTensor(X_valid[:,4].reshape(-1,1)).to(device)\n","    y_visco_valid = torch.FloatTensor(y_valid[:,0].reshape(-1,1)).to(device)\n","\n","    # entropy\n","    x_entro_train = torch.FloatTensor(X_entropy_train[:,0:4]).to(device)\n","    y_entro_train = torch.FloatTensor(y_entropy_train[:,0].reshape(-1,1)).to(device)\n","\n","    x_entro_valid = torch.FloatTensor(X_entropy_valid[:,0:4]).to(device)\n","    y_entro_valid = torch.FloatTensor(y_entropy_valid[:,0].reshape(-1,1)).to(device)\n","\n","    # tg\n","    x_tg_train = torch.FloatTensor(X_tg_train[:,0:4]).to(device)\n","    y_tg_train = torch.FloatTensor(y_tg_train.reshape(-1,1)).to(device)\n","\n","    x_tg_valid = torch.FloatTensor(X_tg_valid[:,0:4]).to(device)\n","    y_tg_valid = torch.FloatTensor(y_tg_valid.reshape(-1,1)).to(device)\n","\n","    # Density\n","    x_density_train = torch.FloatTensor(X_density_train[:,0:4]).to(device)\n","    y_density_train = torch.FloatTensor(y_density_train.reshape(-1,1)).to(device)\n","\n","    x_density_valid = torch.FloatTensor(X_density_valid[:,0:4]).to(device)\n","    y_density_valid = torch.FloatTensor(y_density_valid.reshape(-1,1)).to(device)\n","\n","    # Raman\n","    x_raman_train = torch.FloatTensor(X_raman_train[:,0:4]).to(device)\n","    y_raman_train = torch.FloatTensor(y_raman_train).to(device)\n","\n","    x_raman_valid = torch.FloatTensor(X_raman_valid[:,0:4]).to(device)\n","    y_raman_valid = torch.FloatTensor(y_raman_valid).to(device)\n","\n","    # declaring model\n","    neuralmodel = model(4,nb_neurons,nb_layers,nb_channels_raman,p_drop=p_drop) \n","\n","    # criterion for match\n","    criterion = torch.nn.MSELoss()\n","    criterion.to(device)\n","    optimizer = torch.optim.Adam(neuralmodel.parameters(), lr = 0.001) # optimizer\n","\n","    # we initialize the output bias\n","    neuralmodel.output_bias_init()\n","\n","    # we send the neural net on device\n","    neuralmodel.to(device)\n","    \n","    #\n","    # PRETRAINING\n","    #\n","    neuralmodel.train()\n","\n","    # for early stopping\n","    epoch = 0\n","    best_epoch = 0\n","    val_ex = 0\n","\n","    # for recording losses\n","    record_pretrain_loss = []\n","    record_prevalid_loss = []\n","\n","    while val_ex <= pretrain_patience:\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        y_raman_pred_train = neuralmodel.raman_pred(x_raman_train)\n","        y_density_pred_train = neuralmodel.density(x_density_train)\n","        y_tg_pred_train = neuralmodel.tg(x_tg_train)\n","        y_entro_pred_train = neuralmodel.sctg(x_entro_train)\n","\n","        # on validation set\n","        y_raman_pred_valid = neuralmodel.raman_pred(x_raman_valid)\n","        y_density_pred_valid = neuralmodel.density(x_density_valid)\n","        y_tg_pred_valid = neuralmodel.tg(x_tg_valid)\n","        y_entro_pred_valid = neuralmodel.sctg(x_entro_valid)\n","\n","        # Compute Loss\n","\n","        # train \n","        loss_tg = criterion(y_tg_pred_train, y_tg_train)\n","        loss_raman = criterion(y_raman_pred_train,y_raman_train)\n","        loss_density = criterion(y_density_pred_train,y_density_train)\n","        loss_entro = criterion(y_entro_pred_train,y_entro_train)\n","\n","        loss = 0.001*loss_tg + loss_entro + 10*loss_raman + 1000*loss_density \n","\n","        # validation\n","        loss_tg_v = criterion(y_tg_pred_valid, y_tg_valid)\n","        loss_raman_v = criterion(y_raman_pred_valid,y_raman_valid)\n","        loss_density_v = criterion(y_density_pred_valid,y_density_valid)\n","        loss_entro_v = criterion(y_entro_pred_valid,y_entro_valid)\n","\n","        loss_v = 0.001*loss_tg_v + loss_entro_v + 10*loss_raman_v + 1000*loss_density_v \n","\n","        record_pretrain_loss.append(loss.item())\n","        record_prevalid_loss.append(loss_v.item())\n","\n","        # calculating early-stopping criterion\n","        if epoch == 0:\n","            val_ex = 0\n","            best_loss_v = loss_v.item()\n","        elif loss_v.item() <= best_loss_v:\n","            val_ex = 0\n","            best_epoch = epoch\n","            best_loss_v = loss_v.item()\n","        else:\n","            val_ex += 1\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch += 1\n","                \n","\n","    #\n","    # TRAINING\n","    #\n","    neuralmodel.train()\n","\n","    # for early stopping\n","    epoch = 0\n","    best_epoch = 0\n","    val_ex = 0\n","\n","    # for recording losses\n","    record_train_loss = []\n","    record_valid_loss = []\n","    \n","    while val_ex <= train_patience:\n","      \n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        y_ag_pred_train = neuralmodel.ag(x_visco_train,T_visco_train)\n","        y_myega_pred_train = neuralmodel.myega(x_visco_train,T_visco_train)\n","        y_am_pred_train = neuralmodel.am(x_visco_train,T_visco_train)\n","        y_raman_pred_train = neuralmodel.raman_pred(x_raman_train)\n","        y_density_pred_train = neuralmodel.density(x_density_train)\n","        y_entro_pred_train = neuralmodel.sctg(x_entro_train)\n","\n","        # on validation set\n","        y_ag_pred_valid = neuralmodel.ag(x_visco_valid,T_visco_valid)\n","        y_myega_pred_valid = neuralmodel.myega(x_visco_valid,T_visco_valid)\n","        y_am_pred_valid = neuralmodel.am(x_visco_valid,T_visco_valid)\n","        y_raman_pred_valid = neuralmodel.raman_pred(x_raman_valid)\n","        y_density_pred_valid = neuralmodel.density(x_density_valid)\n","        y_entro_pred_valid = neuralmodel.sctg(x_entro_valid)\n","\n","        # Compute Loss\n","\n","        # train \n","        loss_ag = criterion(y_ag_pred_train, y_visco_train)\n","        loss_myega = criterion(y_myega_pred_train, y_visco_train)\n","        loss_am = criterion(y_am_pred_train, y_visco_train)\n","        loss_raman = criterion(y_raman_pred_train,y_raman_train)\n","        loss_density = criterion(y_density_pred_train,y_density_train)\n","        loss_entro = criterion(y_entro_pred_train,y_entro_train)\n","\n","        loss = loss_entro + loss_ag + loss_myega + loss_am + 10*loss_raman + 1000*loss_density \n","\n","        # validation\n","        loss_ag_v = criterion(y_ag_pred_valid, y_visco_valid)\n","        loss_myega_v = criterion(y_myega_pred_valid, y_visco_valid)\n","        loss_am_v = criterion(y_am_pred_valid, y_visco_valid)\n","        loss_raman_v = criterion(y_raman_pred_valid,y_raman_valid)\n","        loss_density_v = criterion(y_density_pred_valid,y_density_valid)\n","        loss_entro_v = criterion(y_entro_pred_valid,y_entro_valid)\n","\n","        loss_v = loss_entro_v + loss_ag_v + loss_myega_v + loss_am_v + 10*loss_raman_v + 1000*loss_density_v\n","\n","        record_train_loss.append(loss.item())\n","        record_valid_loss.append(loss_v.item())\n","\n","        # calculating ES criterion\n","        if epoch == 0:\n","            val_ex = 0\n","            best_loss_v = loss_v.item()\n","            # save best model\n","            torch.save(neuralmodel.state_dict(), name)\n","        elif loss_v.item() <= best_loss_v:\n","            val_ex = 0\n","            best_epoch = epoch\n","            best_loss_v = loss_v.item()\n","\n","            # save best model\n","            torch.save(neuralmodel.state_dict(), name)\n","        else:\n","            val_ex += 1\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch += 1\n","        \n","    #\n","    # SAVING MODEL\n","    #\n","    \n","    file_out = drive.CreateFile()\n","    # Read file and set it as a content of this instance.\n","    file_out.SetContentFile(name)\n","    file_out.Upload() # Upload the file.\n","    print('Model {} with valid loss {} saved'.format(name,loss_v.item()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjqHVQoqrD4s","colab_type":"code","outputId":"3484c04a-fe48-4dcd-9664-114fed5e7759","executionInfo":{"status":"ok","timestamp":1558058715561,"user_tz":-600,"elapsed":352573,"user":{"displayName":"Charles LL","photoUrl":"","userId":"05619559028255365437"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["path_data = \"./DataSet_0p20val.hdf5\"\n","\n","nb_exp = 10\n","nb_neurons = 300\n","nb_layers = 3\n","p_drop = 0.3\n","\n","for i in range(nb_exp):\n","    print('Experiment {} started...'.format(i))\n","    \n","    path_out = \"loss_ag_myega_am_ram_d_\"+str(i)\n","    \n","    train_model(path_data,nb_neurons,nb_layers,p_drop, path_out, pretrain_patience = 200, train_patience=200)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Experiment 0 started...\n","Model loss_ag_myega_am_ram_d_0 with valid loss 4.101059913635254 saved\n","Experiment 1 started...\n","Model loss_ag_myega_am_ram_d_1 with valid loss 4.481479644775391 saved\n","Experiment 2 started...\n","Model loss_ag_myega_am_ram_d_2 with valid loss 4.885275363922119 saved\n","Experiment 3 started...\n","Model loss_ag_myega_am_ram_d_3 with valid loss 4.606471061706543 saved\n","Experiment 4 started...\n","Model loss_ag_myega_am_ram_d_4 with valid loss 4.100840091705322 saved\n","Experiment 5 started...\n","Model loss_ag_myega_am_ram_d_5 with valid loss 4.145567417144775 saved\n","Experiment 6 started...\n","Model loss_ag_myega_am_ram_d_6 with valid loss 19.383668899536133 saved\n","Experiment 7 started...\n","Model loss_ag_myega_am_ram_d_7 with valid loss 4.690925121307373 saved\n","Experiment 8 started...\n","Model loss_ag_myega_am_ram_d_8 with valid loss 5.580639839172363 saved\n","Experiment 9 started...\n","Model loss_ag_myega_am_ram_d_9 with valid loss 4.376068592071533 saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2NPpxPJtTFoO","colab_type":"code","outputId":"cf9d7b20-c9bb-4f9e-8c65-0b0da0e88eff","executionInfo":{"status":"ok","timestamp":1557990918209,"user_tz":-600,"elapsed":719,"user":{"displayName":"Charles LL","photoUrl":"","userId":"05619559028255365437"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["p_drop\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"7hRiENuXfsTc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
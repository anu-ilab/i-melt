{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load libraries\n",
    "#\n",
    "import pandas as pd # manipulate dataframes\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np\n",
    "\n",
    "import time, h5py, imelt, torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "# First we check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running on {} \".format(device))\n",
    "\n",
    "# Fixing random seeds for reproducibility\n",
    "# np.random.seed = 167 # fix random seed for reproducibility\n",
    "\n",
    "#\n",
    "# USEFUL FUNCTIONS\n",
    "#\n",
    "\n",
    "\n",
    "def train_model(ds, nb_neurons, nb_layers, p_drop, save_name, device, patience=200, min_delta=0.05):\n",
    "    \"\"\"function for practical training of several models\"\"\"\n",
    "    neuralmodel = imelt.model(4,nb_neurons,nb_layers,ds.nb_channels_raman,p_drop=p_drop) # declaring model\n",
    "\n",
    "    optimizer = torch.optim.Adam(neuralmodel.parameters(), lr = 0.0006) # optimizer\n",
    "\n",
    "    # the criterion : MSE\n",
    "    criterion = torch.nn.MSELoss(reduction='mean') # criterion for match, sent on device\n",
    "    criterion.to(device)\n",
    "\n",
    "    neuralmodel.output_bias_init() # we initialize the output bias\n",
    "    neuralmodel = neuralmodel.float() # the model also is in Float\n",
    "    neuralmodel.to(device) # we send the neural net on device\n",
    "    \n",
    "    # training\n",
    "    neuralmodel, record_train_loss, record_valid_loss = imelt.training(neuralmodel,ds,criterion,optimizer,\n",
    "                                                                         save_switch=True,save_name=save_name,\n",
    "                                                                         train_patience=patience,min_delta=min_delta,verbose=False)\n",
    "\n",
    "    # to avoid any problem with CUDA memory...\n",
    "    del neuralmodel, criterion\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "#\n",
    "# DATASET SIZE EXPERIMENT\n",
    "#\n",
    "\n",
    "# paths of data and results\n",
    "path_data = [\"./data/NKAS_viscosity_0p10val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p20val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p30val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p40val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p50val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p60val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p70val.hdf5\",\n",
    "             \"./data/NKAS_viscosity_0p80val.hdf5\"]\n",
    "save_names = [\"./model/exp_trainsize/model_l4_n200_p0_data0p10val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p20val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p30val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p40val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p50val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p60val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p70val\",\n",
    "              \"./model/exp_trainsize/model_l4_n200_p0_data0p80val\"]\n",
    "\n",
    "# the selected architecture\n",
    "nb_neurons = 200\n",
    "nb_layers = 4\n",
    "p_drop = 0.01\n",
    "\n",
    "#\n",
    "# Main loop for the experiment\n",
    "#\n",
    "for i in range(len(path_data)):\n",
    "    print('Experiment on dataset {} started...'.format(i))\n",
    "    ds = imelt.data_loader(path_data[i],\n",
    "                         \"./data/NKAS_Raman.hdf5\",\n",
    "                         \"./data/NKAS_density.hdf5\",\n",
    "                         \"./data/NKAS_optical.hdf5\",\n",
    "                         device)\n",
    "    \n",
    "    for j in tqdm(range(10)):\n",
    "        train_model(ds, nb_neurons, nb_layers, p_drop, \n",
    "                    save_names[i]+\"_{}.pth\".format(j), device)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset size experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879674,
     "status": "ok",
     "timestamp": 1565498592905,
     "user": {
      "displayName": "Charles LL",
      "photoUrl": "",
      "userId": "05619559028255365437"
     },
     "user_tz": -600
    },
    "id": "a2pNE0yNe1CD",
    "outputId": "a85bb203-1d08-4879-84da-02ef81255c0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 0 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:40<00:00, 70.04s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 1 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:01<00:00, 90.19s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 2 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:07<00:00, 84.79s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 3 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:41<00:00, 82.12s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 4 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:53<00:00, 95.32s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 5 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:02<00:00, 54.27s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 6 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [12:14<00:00, 73.50s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on dataset 7 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:28<00:00, 86.85s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1FGNlKke3PC"
   },
   "source": [
    "# Architecture experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [49:07:50<00:00, 58.96s/it]    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Start calculations\n",
    "#\n",
    "nb_exp = 3000\n",
    "nb_neurons = np.random.randint(10,high=500,size=nb_exp)\n",
    "nb_layers = np.random.randint(1,high=7,size=nb_exp)\n",
    "p_drop = np.around(np.random.random_sample(nb_exp)*0.5,2)\n",
    "\n",
    "# custom data loader, automatically sent to device\n",
    "ds = imelt.data_loader(\"./data/NKAS_viscosity_reference.hdf5\",\n",
    "                         \"./data/NKAS_Raman.hdf5\",\n",
    "                         \"./data/NKAS_density.hdf5\",\n",
    "                         \"./data/NKAS_optical.hdf5\",\n",
    "                         device)\n",
    "    \n",
    "for i in tqdm(range(nb_exp)):\n",
    "        \n",
    "    # name for saving\n",
    "    name = \"./model/exp_arch/l\"+str(nb_layers[i])+\"_n\"+str(nb_neurons[i])+\"_p\"+str(p_drop[i])+\".pth\"\n",
    "    \n",
    "    train_model(ds,nb_neurons[i],nb_layers[i],p_drop[i], name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_datasetsize_exp.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maVRVSAFHDwa"
   },
   "outputs": [],
   "source": [
    "#!pip install -U -q PyDrive\n",
    "\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2670,
     "status": "ok",
     "timestamp": 1558055182469,
     "user": {
      "displayName": "Charles LL",
      "photoUrl": "",
      "userId": "05619559028255365437"
     },
     "user_tz": -600
    },
    "id": "e0SePNd0dLJc",
    "outputId": "abffa3fe-ec5e-4ed2-ac84-97bd796b8b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVAILABLE?  True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Library loading\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd # manipulate dataframes\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib, time, h5py, torch, neuravi\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# First we check if CUDA is available\n",
    "print(\"CUDA AVAILABLE? \",torch.cuda.is_available())\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "      \n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U13abpURpfDw"
   },
   "source": [
    "# General function\n",
    "\n",
    "For this one we use custom training functions (as we will change the objective function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(neuralmodel,ds,criterion,optimizer,save_name,train_patience = 50,verbose=True, mode=\"main\"):\n",
    "    if verbose == True:\n",
    "        time1 = time.time()\n",
    "        \n",
    "        if mode == \"pretrain\":\n",
    "            print(\"! Pretrain mode...\\n\")\n",
    "        else:\n",
    "            print(\"Full training.\\n\")\n",
    "\n",
    "    neuralmodel.train()\n",
    "\n",
    "    # for early stopping\n",
    "    epoch = 0\n",
    "    best_epoch = 0\n",
    "    val_ex = 0\n",
    "\n",
    "    # for recording losses\n",
    "    record_train_loss = []\n",
    "    record_valid_loss = []\n",
    "\n",
    "    while val_ex <= train_patience:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_ag_pred_train = neuralmodel.ag(ds.x_visco_train,ds.T_visco_train)\n",
    "        y_myega_pred_train = neuralmodel.myega(ds.x_visco_train,ds.T_visco_train)\n",
    "        y_am_pred_train = neuralmodel.am(ds.x_visco_train,ds.T_visco_train)\n",
    "        y_cg_pred_train = neuralmodel.cg(ds.x_visco_train,ds.T_visco_train)\n",
    "        y_raman_pred_train = neuralmodel.raman_pred(ds.x_raman_train)\n",
    "        y_density_pred_train = neuralmodel.density(ds.x_density_train)\n",
    "        y_entro_pred_train = neuralmodel.sctg(ds.x_entro_train)\n",
    "        y_tg_pred_train = neuralmodel.tg(ds.x_tg_train)\n",
    "        y_cp_pred_train = neuralmodel.dCp(ds.x_entro_train,neuralmodel.tg(ds.x_entro_train))\n",
    "        y_ri_pred_train = neuralmodel.sellmeier(ds.x_ri_train, ds.lbd_ri_train)\n",
    "        \n",
    "        # on validation set\n",
    "        y_ag_pred_valid = neuralmodel.ag(ds.x_visco_valid,ds.T_visco_valid)\n",
    "        y_myega_pred_valid = neuralmodel.myega(ds.x_visco_valid,ds.T_visco_valid)\n",
    "        y_am_pred_valid = neuralmodel.am(ds.x_visco_valid,ds.T_visco_valid)\n",
    "        y_cg_pred_valid = neuralmodel.cg(ds.x_visco_valid,ds.T_visco_valid)\n",
    "        y_raman_pred_valid = neuralmodel.raman_pred(ds.x_raman_valid)\n",
    "        y_density_pred_valid = neuralmodel.density(ds.x_density_valid)\n",
    "        y_entro_pred_valid = neuralmodel.sctg(ds.x_entro_valid)\n",
    "        y_tg_pred_valid = neuralmodel.tg(ds.x_tg_valid)\n",
    "        y_cp_pred_valid = neuralmodel.dCp(ds.x_entro_valid,neuralmodel.tg(ds.x_entro_valid))\n",
    "        y_ri_pred_valid = neuralmodel.sellmeier(ds.x_ri_valid, ds.lbd_ri_valid)\n",
    "        \n",
    "        # Compute Loss\n",
    "\n",
    "        # train\n",
    "        loss_ag = criterion(y_ag_pred_train, ds.y_visco_train)\n",
    "        loss_myega = criterion(y_myega_pred_train, ds.y_visco_train)\n",
    "        loss_am = criterion(y_am_pred_train, ds.y_visco_train)\n",
    "        loss_cg = criterion(y_cg_pred_train, ds.y_visco_train)\n",
    "        loss_raman = criterion(y_raman_pred_train,ds.y_raman_train)\n",
    "        loss_tg = criterion(y_tg_pred_train,ds.y_tg_train)\n",
    "        loss_density = criterion(y_density_pred_train,ds.y_density_train)\n",
    "        loss_entro = criterion(y_entro_pred_train,ds.y_entro_train)\n",
    "        loss_ri = criterion(y_ri_pred_train,ds.y_ri_train)\n",
    "        \n",
    "        if mode == \"pretrain\":\n",
    "            loss = 0.001*loss_tg #+ 10*loss_raman #+ 1000*loss_density #+ loss_entro #+ loss_ri*1000\n",
    "        else:\n",
    "            loss = loss_ag + loss_myega + loss_am + loss_cg #+ 10*loss_raman #+ 1000*loss_density #+ loss_entro #+ loss_ri*1000\n",
    "\n",
    "        # validation\n",
    "        loss_ag_v = criterion(y_ag_pred_valid, ds.y_visco_valid)\n",
    "        loss_myega_v = criterion(y_myega_pred_valid, ds.y_visco_valid)\n",
    "        loss_am_v = criterion(y_am_pred_valid, ds.y_visco_valid)\n",
    "        loss_cg_v = criterion(y_cg_pred_valid, ds.y_visco_valid)\n",
    "        loss_raman_v = criterion(y_raman_pred_valid,ds.y_raman_valid)\n",
    "        loss_tg_v = criterion(y_tg_pred_valid,ds.y_tg_valid)\n",
    "        loss_density_v = criterion(y_density_pred_valid,ds.y_density_valid)\n",
    "        loss_entro_v = criterion(y_entro_pred_valid,ds.y_entro_valid)\n",
    "        loss_ri_v = criterion(y_ri_pred_valid,ds.y_ri_valid)\n",
    "\n",
    "        if mode == \"pretrain\":\n",
    "            loss_v = 0.001*loss_tg_v #+ 10*loss_raman_v #+ 1000*loss_density_v #+ loss_entro_v #+ loss_ri_v*1000\n",
    "        else:\n",
    "            loss_v = loss_ag_v + loss_myega_v + loss_am_v + loss_cg_v #+ 10*loss_raman_v #+ 1000*loss_density_v #+ loss_entro_v #+ loss_ri*1000\n",
    "\n",
    "        record_train_loss.append(loss.item())\n",
    "        record_valid_loss.append(loss_v.item())\n",
    "\n",
    "        if verbose == True:\n",
    "            if (epoch % 200 == 0):\n",
    "              print('Epoch {} => train loss: {}; valid loss: {}'.format(epoch, loss.item(), loss_v.item()))\n",
    "\n",
    "        # calculating ES criterion\n",
    "        if epoch == 0:\n",
    "            val_ex = 0\n",
    "            best_loss_v = loss_v.item()\n",
    "        elif loss_v.item() <= best_loss_v:\n",
    "            val_ex = 0\n",
    "            best_epoch = epoch\n",
    "            best_loss_v = loss_v.item()\n",
    "\n",
    "            # save best model\n",
    "            torch.save(neuralmodel.state_dict(), save_name)\n",
    "        else:\n",
    "            val_ex += 1\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    if verbose == True:\n",
    "        time2 = time.time()\n",
    "        print(\"Running time in seconds:\", time2-time1)\n",
    "\n",
    "    return neuralmodel, record_train_loss, record_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "ds = neuravi.data_loader(\"./data/DataSet_0p20val.hdf5\",\n",
    "                         \"./data/NKAS_Raman.hdf5\",\n",
    "                         \"./data/NKAS_density.hdf5\",\n",
    "                         \"./data/NKAS_optical.hdf5\",device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 352573,
     "status": "ok",
     "timestamp": 1558058715561,
     "user": {
      "displayName": "Charles LL",
      "photoUrl": "",
      "userId": "05619559028255365437"
     },
     "user_tz": -600
    },
    "id": "sjqHVQoqrD4s",
    "outputId": "3484c04a-fe48-4dcd-9664-114fed5e7759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 0 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 46.19532012939453; valid loss: 61.42976379394531\n",
      "Epoch 200 => train loss: 0.8780887722969055; valid loss: 1.2617266178131104\n",
      "Running time in seconds: 6.158773183822632\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 5.872018814086914; valid loss: 7.443633079528809\n",
      "Running time in seconds: 8.3176109790802\n",
      "Experiment 1 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 46.76251220703125; valid loss: 63.8747444152832\n",
      "Epoch 200 => train loss: 0.9418908953666687; valid loss: 1.3002619743347168\n",
      "Running time in seconds: 7.472977876663208\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 5.349086284637451; valid loss: 6.946389198303223\n",
      "Running time in seconds: 4.361438751220703\n",
      "Experiment 2 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 49.54499816894531; valid loss: 54.52342987060547\n",
      "Epoch 200 => train loss: 1.0473253726959229; valid loss: 1.5573610067367554\n",
      "Epoch 400 => train loss: 0.4805125892162323; valid loss: 0.7145112752914429\n",
      "Running time in seconds: 11.310808181762695\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 5.667484283447266; valid loss: 7.205848693847656\n",
      "Epoch 200 => train loss: 0.6501432657241821; valid loss: 0.999661386013031\n",
      "Running time in seconds: 11.293451070785522\n",
      "Experiment 3 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 47.74055099487305; valid loss: 61.44001388549805\n",
      "Epoch 200 => train loss: 1.1769354343414307; valid loss: 0.9786551594734192\n",
      "Epoch 400 => train loss: 0.4680975079536438; valid loss: 0.9776974320411682\n",
      "Running time in seconds: 8.91363787651062\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 5.693842887878418; valid loss: 7.067181587219238\n",
      "Running time in seconds: 8.218659162521362\n",
      "Experiment 4 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 46.08600616455078; valid loss: 65.40103912353516\n",
      "Epoch 200 => train loss: 1.029667854309082; valid loss: 1.4293781518936157\n",
      "Epoch 400 => train loss: 0.48503416776657104; valid loss: 0.8081241250038147\n",
      "Running time in seconds: 11.88810658454895\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 5.44188117980957; valid loss: 6.704254627227783\n",
      "Running time in seconds: 5.485302686691284\n",
      "Experiment 5 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 46.258792877197266; valid loss: 59.82344436645508\n",
      "Epoch 200 => train loss: 1.0707076787948608; valid loss: 2.147465944290161\n",
      "Running time in seconds: 7.361682653427124\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 6.328752517700195; valid loss: 7.983190536499023\n",
      "Epoch 200 => train loss: 0.8613466620445251; valid loss: 1.2148486375808716\n",
      "Running time in seconds: 6.9859619140625\n",
      "Experiment 6 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 47.305564880371094; valid loss: 58.739654541015625\n",
      "Epoch 200 => train loss: 0.875615119934082; valid loss: 1.4046138525009155\n",
      "Running time in seconds: 8.346385955810547\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 5.489089488983154; valid loss: 7.42271614074707\n",
      "Running time in seconds: 9.118659973144531\n",
      "Experiment 7 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 49.116539001464844; valid loss: 52.290348052978516\n",
      "Epoch 200 => train loss: 1.2686516046524048; valid loss: 1.7338573932647705\n",
      "Epoch 400 => train loss: 0.6230559945106506; valid loss: 0.9165812730789185\n",
      "Running time in seconds: 18.27115225791931\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 6.1688032150268555; valid loss: 7.885765075683594\n",
      "Running time in seconds: 9.319330930709839\n",
      "Experiment 8 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 46.429378509521484; valid loss: 62.92623519897461\n",
      "Epoch 200 => train loss: 1.1561040878295898; valid loss: 1.0876544713974\n",
      "Running time in seconds: 13.467892408370972\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 6.026054382324219; valid loss: 7.635923862457275\n",
      "Running time in seconds: 6.065788984298706\n",
      "Experiment 9 started...\n",
      "! Pretrain mode...\n",
      "\n",
      "Epoch 0 => train loss: 47.306427001953125; valid loss: 56.88192367553711\n",
      "Epoch 200 => train loss: 1.2535837888717651; valid loss: 1.7569087743759155\n",
      "Running time in seconds: 14.106563806533813\n",
      "Full training.\n",
      "\n",
      "Epoch 0 => train loss: 6.800486087799072; valid loss: 8.595720291137695\n",
      "Running time in seconds: 11.27198600769043\n"
     ]
    }
   ],
   "source": [
    "nb_exp = 10\n",
    "\n",
    "for i in range(nb_exp):\n",
    "    print('Experiment {} started...'.format(i))\n",
    "    \n",
    "    path_out = \"./model/exp_multitask/loss_ag_myega_am_cg_\"+str(i)+\".pth\"\n",
    "    \n",
    "    # Network declaration\n",
    "    neuralmodel = neuravi.model(4,200,3,ds.nb_channels_raman,p_drop=0.05) \n",
    "\n",
    "    # criterion for match\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    criterion.to(device)\n",
    "    optimizer = torch.optim.Adam(neuralmodel.parameters(), lr = 0.001) # optimizer\n",
    "\n",
    "    # we initialize the output bias\n",
    "    neuralmodel.output_bias_init()\n",
    "\n",
    "    # we send the neural net on device\n",
    "    neuralmodel.to(device)\n",
    "    \n",
    "    neuralmodel, record_pretrain_loss, record_prevalid_loss = training(neuralmodel,ds,criterion,optimizer,path_out,mode=\"pretrain\")\n",
    "    neuralmodel, record_train_loss, record_valid_loss = training(neuralmodel,\n",
    "                                                                         ds,\n",
    "                                                                         criterion,optimizer,\n",
    "                                                                         path_out,verbose=True,\n",
    "                                                                         train_patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1557990918209,
     "user": {
      "displayName": "Charles LL",
      "photoUrl": "",
      "userId": "05619559028255365437"
     },
     "user_tz": -600
    },
    "id": "2NPpxPJtTFoO",
    "outputId": "cf9d7b20-c9bb-4f9e-8c65-0b0da0e88eff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hRiENuXfsTc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_loss_experiment.ipynb",
   "provenance": [
    {
     "file_id": "1pyCJHFWF3kQnPEODWuaOJ_CNv3Xpl7iS",
     "timestamp": 1557992100097
    },
    {
     "file_id": "1EwabwOAxjcKaayDdcgvKHS-8H9MkCJSn",
     "timestamp": 1557905521210
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
